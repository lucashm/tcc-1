{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing lybraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "esport\n"
     ]
    }
   ],
   "source": [
    "# !pip3 install stop-words\n",
    "# !pip3 install snowballstemmer\n",
    "\n",
    "import stop_words\n",
    "import snowballstemmer\n",
    "\n",
    "stop_words.get_stop_words('pt')\n",
    "stemmer = snowballstemmer.stemmer('portuguese')\n",
    "print(stemmer.stemWord('esportistas'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import arff\n",
    "from io import StringIO\n",
    "from sklearn.model_selection import train_test_split\n",
    "from textblob.classifiers import NaiveBayesClassifier, DecisionTreeClassifier, MaxEntClassifier\n",
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing and setting up hatespeech dataset for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = arff.load(open('OffComBR3.arff'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data['data'])\n",
    "df.columns = ['hate', 'sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_string_boolen_to_int(x):\n",
    "    if x == 'yes':\n",
    "        retorno = 1\n",
    "    elif x == 'no':\n",
    "        retorno = 0\n",
    "    else:\n",
    "        retorno = x\n",
    "    return retorno\n",
    "df['hate'] = df['hate'].apply(transform_string_boolen_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['hate'], axis=1)\n",
    "y = df['sentence']\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X.values,y,test_size=0.33)\n",
    "train = df.iloc[:723, :]\n",
    "test = df.iloc[723:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this method return the traing data in the TextBlob recommended format\n",
    "def  build_txblob_array (data):\n",
    "    txb_array = []\n",
    "    for d in data.iterrows():\n",
    "        new_data = (d[1][1], d[1][0])\n",
    "        txb_array.append(new_data)\n",
    "    return(txb_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building arrays to train and test the textBlob's NaiveBayesClassifier\n",
    "train_array = build_txblob_array(train)\n",
    "test_array = build_txblob_array(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating different classifiers and getting its accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating classifier\n",
    "cl_nb = NaiveBayesClassifier(train_array)\n",
    "cl_dt = DecisionTreeClassifier(train_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6129032258064516"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing classifier\n",
    "cl_nb.accuracy(test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6419354838709678"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl_dt.accuracy(test_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset experiments to improve classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/marco/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package rslp to /home/marco/nltk_data...\n",
      "[nltk_data]   Unzipping stemmers/rslp.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('rslp')\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "stemmer = nltk.stem.RSLPStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Votaram no PEZAO Agora tomem no CZAO', 1),\n",
       " ('cuidado com a poupanca pessoal Lembram o que aconteceu na epoca do Collor ne',\n",
       "  0),\n",
       " ('Sabe o que eu acho engracado os nossos governantes  nao pensam em cortar regalias e beneficios desnecessarios que os favorecem porque sera ne e mais do que claro ate mesmo para quem nao quer enxergar eles sao estao la para defender seus proprios interesses  e os dos empresario o no casso eles tambem ou comecamos a tomar uma atitude para mudar de uma vez por todas essa roubalheira nesse pais o a tendencia e so piorar para o povo porque dinheiro para investimentos nao tem mais para aumentos de salario e regalias nao falta',\n",
       "  0),\n",
       " ('Podiam retirar dos lucros dos bancos ', 0),\n",
       " ('CADE O GALVAO PRA NARRAR AGORA   FALIIIIUUUUUUU FALIIIUUUUUUU FALIIUUUUUUU  ',\n",
       "  0)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_array[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lowering the case, removing stopwords and stemming words to get cleaner sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_array(array):\n",
    "    n_array = []\n",
    "    for cell in array:\n",
    "        text = ''\n",
    "        #text = nltk.word_tokenize(w.lower() for w in nltk.word_tokenize(cell[0]) if w not in stopwords)\n",
    "        for w in nltk.word_tokenize(cell[0]):\n",
    "            if w not in stopwords:\n",
    "                text = text + stemmer.stem(w) + ' '\n",
    "        n_cell = (text.strip(), cell[1])\n",
    "        n_array.append(n_cell) \n",
    "    return n_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = clean_array(train_array)\n",
    "new_test = clean_array(test_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating new classifiers with the cleanner dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cl_nb = NaiveBayesClassifier(new_train)\n",
    "new_cl_dt = DecisionTreeClassifier(new_train)\n",
    "new_cl_mc = MaxEntClassifier(new_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6129032258064516"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_cl_nb.accuracy(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6741935483870968"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_cl_dt.accuracy(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
