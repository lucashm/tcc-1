{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arff\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import attrgetter, itemgetter\n",
    "from io import StringIO\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import tree\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import make_scorer, confusion_matrix,classification_report,precision_recall_fscore_support as score, average_precision_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "## training model\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recal_1(y_true, y_pred):\n",
    "    precision, recall, fscore, support = score(y_true, y_pred)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    return(recall[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/marco/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package rslp to /home/marco/nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/marco/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('rslp')\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "def clean_text(txt):\n",
    "    text = ''\n",
    "    for w in nltk.word_tokenize(txt):\n",
    "        if w not in stopwords:\n",
    "            text = text + stemmer.stem(w) + ' '\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marco/tcc/env_tcc/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/marco/tcc/env_tcc/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89       167\n",
      "           1       0.00      0.00      0.00        41\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       208\n",
      "   macro avg       0.40      0.50      0.45       208\n",
      "weighted avg       0.64      0.80      0.72       208\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89       166\n",
      "           1       0.00      0.00      0.00        41\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       207\n",
      "   macro avg       0.40      0.50      0.45       207\n",
      "weighted avg       0.64      0.80      0.71       207\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89       166\n",
      "           1       0.00      0.00      0.00        40\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       206\n",
      "   macro avg       0.40      0.50      0.45       206\n",
      "weighted avg       0.65      0.81      0.72       206\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89       166\n",
      "           1       0.00      0.00      0.00        40\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       206\n",
      "   macro avg       0.40      0.50      0.45       206\n",
      "weighted avg       0.65      0.81      0.72       206\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89       166\n",
      "           1       0.00      0.00      0.00        40\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       206\n",
      "   macro avg       0.40      0.50      0.45       206\n",
      "weighted avg       0.65      0.81      0.72       206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = arff.load(open('../OffComBR3.arff'))\n",
    "df = pd.DataFrame(data['data'])\n",
    "df.columns = ['hate', 'sentence']\n",
    "\n",
    "# transforming 'yes' into 1 and 'no' into 0\n",
    "df['hate'] = df['hate'].apply(lambda x: 1 if x == 'yes' else 0)\n",
    "\n",
    "X = df['sentence'].tolist()\n",
    "y = df['hate'].tolist()\n",
    "\n",
    "cl =  Pipeline([\n",
    "        ('tfidf',TfidfVectorizer()),\n",
    "        ('clf', SVC()),\n",
    "        ])\n",
    "\n",
    "scores = cross_validate(cl, X, y,\n",
    "                        cv=5, return_train_score=False, scoring=make_scorer(get_recal_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fase 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marco/tcc/env_tcc/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/marco/tcc/env_tcc/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89       167\n",
      "           1       0.00      0.00      0.00        41\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       208\n",
      "   macro avg       0.40      0.50      0.45       208\n",
      "weighted avg       0.64      0.80      0.72       208\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89       166\n",
      "           1       0.00      0.00      0.00        41\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       207\n",
      "   macro avg       0.40      0.50      0.45       207\n",
      "weighted avg       0.64      0.80      0.71       207\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89       166\n",
      "           1       0.00      0.00      0.00        40\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       206\n",
      "   macro avg       0.40      0.50      0.45       206\n",
      "weighted avg       0.65      0.81      0.72       206\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89       166\n",
      "           1       0.00      0.00      0.00        40\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       206\n",
      "   macro avg       0.40      0.50      0.45       206\n",
      "weighted avg       0.65      0.81      0.72       206\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89       166\n",
      "           1       0.00      0.00      0.00        40\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       206\n",
      "   macro avg       0.40      0.50      0.45       206\n",
      "weighted avg       0.65      0.81      0.72       206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = arff.load(open('../OffComBR3.arff'))\n",
    "df = pd.DataFrame(data['data'])\n",
    "df.columns = ['hate', 'sentence']\n",
    "\n",
    "# transforming 'yes' into 1 and 'no' into 0\n",
    "df['hate'] = df['hate'].apply(lambda x: 1 if x == 'yes' else 0)\n",
    "\n",
    "X = df['sentence'].tolist()\n",
    "y = df['hate'].tolist()\n",
    "\n",
    "## Cleaning text before\n",
    "\n",
    "for i in range(len(X)):\n",
    "    n_txt = clean_text(X[i])\n",
    "    X[i] = n_txt\n",
    "    \n",
    "cl =  Pipeline([\n",
    "        ('tfidf',TfidfVectorizer()),\n",
    "        ('clf', SVC()),\n",
    "        ])\n",
    "\n",
    "scores = cross_validate(cl, X, y,\n",
    "                        cv=5, return_train_score=False, scoring=make_scorer(get_recal_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fase 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4208536585365854\n",
      "{'clf__C': 4, 'clf__kernel': 'linear', 'clf__probability': True, 'clf__shrinking': True, 'clf__tol': 1, 'tfidf__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "data = arff.load(open('../OffComBR3.arff'))\n",
    "df = pd.DataFrame(data['data'])\n",
    "df.columns = ['hate', 'sentence']\n",
    "\n",
    "# transforming 'yes' into 1 and 'no' into 0\n",
    "df['hate'] = df['hate'].apply(lambda x: 1 if x == 'yes' else 0)\n",
    "\n",
    "X = df['sentence'].tolist()\n",
    "y = df['hate'].tolist()\n",
    "\n",
    "## Cleaning text before\n",
    "\n",
    "for i in range(len(X)):\n",
    "    n_txt = clean_text(X[i])\n",
    "    X[i] = n_txt\n",
    "    \n",
    "cl =  Pipeline([\n",
    "        ('tfidf',TfidfVectorizer()),\n",
    "        ('clf', SVC()),\n",
    "        ])\n",
    "    \n",
    "parameters = {'tfidf__ngram_range': [(1,1), (1,2), (1,3), (1,4)],\n",
    "              'clf__C': (1, 2, 3, 4, 5),\n",
    "              'clf__kernel': ('rbf', 'linear', 'poly', 'sigmoid'),\n",
    "              'clf__shrinking': (True, False),\n",
    "              'clf__probability': (True, False),\n",
    "              'clf__tol': (1e-4, 1e-3, 1e-2, 0.1, 1)\n",
    "             }\n",
    "\n",
    "gs_clf = GridSearchCV(cl, parameters, cv=5, iid=False, n_jobs=-1, scoring='recall')\n",
    "\n",
    "gs_clf.fit(X, y)\n",
    "print(gs_clf.best_score_)\n",
    "print(gs_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90       167\n",
      "           1       0.62      0.37      0.46        41\n",
      "\n",
      "   micro avg       0.83      0.83      0.83       208\n",
      "   macro avg       0.74      0.66      0.68       208\n",
      "weighted avg       0.81      0.83      0.81       208\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87       166\n",
      "           1       0.46      0.46      0.46        41\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       207\n",
      "   macro avg       0.67      0.67      0.67       207\n",
      "weighted avg       0.79      0.79      0.79       207\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91       166\n",
      "           1       0.62      0.50      0.56        40\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       206\n",
      "   macro avg       0.76      0.71      0.73       206\n",
      "weighted avg       0.83      0.84      0.84       206\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88       166\n",
      "           1       0.50      0.45      0.47        40\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       206\n",
      "   macro avg       0.69      0.67      0.68       206\n",
      "weighted avg       0.80      0.81      0.80       206\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.86       166\n",
      "           1       0.41      0.33      0.36        40\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       206\n",
      "   macro avg       0.63      0.61      0.61       206\n",
      "weighted avg       0.76      0.78      0.77       206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cl =  Pipeline([\n",
    "        ('tfidf',TfidfVectorizer(ngram_range=(1, 1))),\n",
    "        ('clf', SVC(C=4, kernel='linear', probability=True, shrinking=True, tol=1)),\n",
    "        ])\n",
    "\n",
    "scores = cross_validate(cl, X, y,\n",
    "                        cv=5, return_train_score=False, scoring=make_scorer(get_recal_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
