{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Experiments_Bagging.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UCXyycm-Qh3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "164570d6-9aa4-4406-f102-0c8df93775fb"
      },
      "source": [
        "# !! pip install arff"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Collecting arff',\n",
              " '  Downloading https://files.pythonhosted.org/packages/50/de/62d4446c5a6e459052c2f2d9490c370ddb6abc0766547b4cef585913598d/arff-0.9.tar.gz',\n",
              " 'Building wheels for collected packages: arff',\n",
              " '  Building wheel for arff (setup.py) ... \\x1b[?25l\\x1b[?25hdone',\n",
              " '  Stored in directory: /root/.cache/pip/wheels/04/d0/70/2c73afedd3ac25c6085b528742c69b9587cbdfa67e5194583b',\n",
              " 'Successfully built arff',\n",
              " 'Installing collected packages: arff',\n",
              " 'Successfully installed arff-0.9']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFQac2wr-LNy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import arff\n",
        "import numpy as np\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "from operator import attrgetter, itemgetter\n",
        "from io import StringIO\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn import tree\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import make_scorer, confusion_matrix,classification_report,precision_recall_fscore_support as score, average_precision_score\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_validate\n",
        "from pickle import Pickler, Unpickler\n",
        "\n",
        "## training model\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, BaggingClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAIR83pK-xmT",
        "colab_type": "code",
        "outputId": "1bcc201e-40f4-437f-d3c3-01bddc1d0fb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D64VUJKt-ZiK",
        "colab_type": "code",
        "outputId": "58c8fa6e-9478-44c4-9074-6668d6cd4cc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "root_path = \"gdrive/My Drive/Colab Notebooks/\"\n",
        "df = Unpickler(open(root_path + \"dataset/OffComBR3.sav\", 'rb')).load()\n",
        "\n",
        "X = df['sentence'].tolist()\n",
        "y = df['hate'].tolist()\n",
        "\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('rslp')\n",
        "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
        "stemmer = nltk.stem.RSLPStemmer()\n",
        "nltk.download('punkt')\n",
        "\n",
        "def clean_text(txt):\n",
        "    text = ''\n",
        "    for w in nltk.word_tokenize(txt):\n",
        "        if w not in stopwords:\n",
        "            text = text + stemmer.stem(w) + ' '\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "for i in range(len(X)):\n",
        "    n_txt = clean_text(X[i])\n",
        "    X[i] = n_txt\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "                                X, y, test_size=0.33, random_state=42)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Package rslp is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zdsHaWAHvB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifiers = [DecisionTreeClassifier(), MLPClassifier(), MultinomialNB(), RandomForestClassifier(), SGDClassifier(), SVC()]\n",
        "# classifiers = [SVC()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_QO63H6PW-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_recal_1(y_true, y_pred):\n",
        "    precision, recall, fscore, support = score(y_true, y_pred)\n",
        "#     print(classification_report(y_true, y_pred))\n",
        "    return(recall[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exf-5n2tTw2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## classificadores com os melhores hiperparametros\n",
        "\n",
        "dt =  [TfidfVectorizer(max_df = 0.6,\n",
        "                                 min_df = 1,\n",
        "                                 ngram_range = (1, 1),\n",
        "                                 smooth_idf = True,\n",
        "                                 strip_accents = 'ascii',\n",
        "                                 sublinear_tf = False,\n",
        "                                 use_idf = True),\n",
        "        DecisionTreeClassifier(class_weight= {0: 1, 1: 2}, criterion= 'gini', min_samples_split = 3),\n",
        "      False, 0.5, 0.2, 2]\n",
        "\n",
        "\n",
        "mlp =  [TfidfVectorizer(max_df= 0.2,\n",
        "                                 min_df= 5,\n",
        "                                 ngram_range= (1, 2),\n",
        "                                 smooth_idf= True,\n",
        "                                 strip_accents= 'ascii',\n",
        "                                 sublinear_tf= False,\n",
        "                                 use_idf = False),\n",
        "        MLPClassifier(activation='logistic', alpha= 0, solver='lbfgs'),\n",
        "       True, 1.0, 1.0, 10]\n",
        "\n",
        "\n",
        "mnb =  [TfidfVectorizer(max_df= 0.6,\n",
        "                                 min_df= 5,\n",
        "                                 ngram_range= (1, 1),\n",
        "                                 smooth_idf= True,\n",
        "                                 strip_accents= 'ascii',\n",
        "                                 sublinear_tf= True,\n",
        "                                 use_idf = True),\n",
        "        MultinomialNB(alpha=0.1, fit_prior=False),\n",
        "       False, 0.2, 1.0, 7]\n",
        "\n",
        "rf = [TfidfVectorizer(max_df= 0.2,\n",
        "                                 min_df= 2,\n",
        "                                 ngram_range= (1, 1),\n",
        "                                 smooth_idf= False,\n",
        "                                 strip_accents= 'ascii',\n",
        "                                 sublinear_tf= True,\n",
        "                                 use_idf = True),\n",
        "        RandomForestClassifier(max_depth=None, min_samples_leaf= 1, min_samples_split= 2, n_estimators=100),\n",
        "     False, 0.9, 1.0, 10]\n",
        "\n",
        "\n",
        "sgd = [TfidfVectorizer(max_df= 0.2,\n",
        "                                 min_df= 10,\n",
        "                                 ngram_range= (1, 3),\n",
        "                                 smooth_idf= True,\n",
        "                                 strip_accents= 'ascii',\n",
        "                                 sublinear_tf= True,\n",
        "                                 use_idf = False),\n",
        "       SGDClassifier(alpha=0.01, loss='perceptron', penalty='none'),\n",
        "      True, 1.0, 0.9, 7]\n",
        "\n",
        "\n",
        "svc =  [TfidfVectorizer(max_df= 0.6,\n",
        "                                 min_df= 1,\n",
        "                                 ngram_range= (1, 1),\n",
        "                                 smooth_idf= True,\n",
        "                                 strip_accents= 'ascii',\n",
        "                                 sublinear_tf= False,\n",
        "                                 use_idf = True),\n",
        "        SVC(C=4, kernel ='linear', probability=True, shrinking=True, tol=1),\n",
        "       False, 1.0, 1.0, 4]\n",
        "\n",
        "# improved_classifiers = [('dt', dt), ('mlp', mlp), ('mnb', mnb), ('rf', rf), ('sgd', sgd), ('svc', svc)]\n",
        "improved_classifiers = [dt, mlp, mnb, rf, sgd, svc]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swINe0sIJnEU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "9493269e-f941-48c4-8f27-89c19854f6c0"
      },
      "source": [
        "## Otimizando hiperparâmetros do Bagging\n",
        "\n",
        "for classifier in improved_classifiers:\n",
        "\n",
        "  bagging = Pipeline([\n",
        "          ('tfidf', classifier[0]),\n",
        "          ('bag', BaggingClassifier(base_estimator=classifier[1]))\n",
        "       ])\n",
        "\n",
        "  bagging_parameters = {\n",
        "      'bag__n_estimators' : [2, 4, 7, 10],\n",
        "      'bag__max_samples' : [0.2, 0.5, 0.9, 1.0],\n",
        "      'bag__max_features' : [0.2, 0.5, 0.9, 1.0],\n",
        "      'bag__bootstrap' : [True, False]\n",
        "  }\n",
        "\n",
        "\n",
        "  gs = GridSearchCV(bagging, bagging_parameters, cv=5, iid=False, n_jobs=-1, scoring='recall')\n",
        "  gs.fit(X, y)\n",
        "  print(classifier[1].__class__.__name__)\n",
        "  print(gs.best_score_)\n",
        "  print(gs.best_params_)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DecisionTreeClassifier\n",
            "0.4909756097560975\n",
            "{'bag__bootstrap': False, 'bag__max_features': 0.5, 'bag__max_samples': 0.2, 'bag__n_estimators': 2}\n",
            "MLPClassifier\n",
            "0.4315853658536585\n",
            "{'bag__bootstrap': True, 'bag__max_features': 1.0, 'bag__max_samples': 1.0, 'bag__n_estimators': 10}\n",
            "MultinomialNB\n",
            "0.5698780487804879\n",
            "{'bag__bootstrap': False, 'bag__max_features': 0.2, 'bag__max_samples': 1.0, 'bag__n_estimators': 7}\n",
            "RandomForestClassifier\n",
            "0.3119512195121951\n",
            "{'bag__bootstrap': False, 'bag__max_features': 0.9, 'bag__max_samples': 1.0, 'bag__n_estimators': 10}\n",
            "SGDClassifier\n",
            "0.37121951219512195\n",
            "{'bag__bootstrap': True, 'bag__max_features': 1.0, 'bag__max_samples': 0.9, 'bag__n_estimators': 7}\n",
            "SVC\n",
            "0.31670731707317074\n",
            "{'bag__bootstrap': False, 'bag__max_features': 1.0, 'bag__max_samples': 1.0, 'bag__n_estimators': 4}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57iFCCgG0qG9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ef3e4da3-7138-4026-8cc8-104b067cd6c8"
      },
      "source": [
        "## Testando bagging com parâmetros otimizados\n",
        "\n",
        "for classifier in improved_classifiers:\n",
        "\n",
        "  bagging = Pipeline([\n",
        "          ('tfidf', classifier[0]),\n",
        "          ('bag', BaggingClassifier(base_estimator=classifier[1],\n",
        "                                    bootstrap=classifier[2],\n",
        "                                    max_features=classifier[3],\n",
        "                                    max_samples=classifier[4],\n",
        "                                    n_estimators=classifier[5]))\n",
        "       ])\n",
        "  print(classifier[1].__class__.__name__)\n",
        "  \n",
        "  bagging.fit(X_train, y_train) \n",
        "  ## Report normal\n",
        "  pred = bagging.predict(X_test)\n",
        "  print(classification_report(y_test, pred))\n",
        "  \n",
        "  precision = cross_val_score(bagging, X, y, cv=10, scoring='precision')\n",
        "  print(\"Precision: %0.2f (+/- %0.2f) [%s]\" % (precision.mean(), precision.std(), classifier[1].__class__.__name__))\n",
        "  recall = cross_val_score(bagging, X, y, cv=10, scoring='recall')\n",
        "  print(\"Recall: %0.2f (+/- %0.2f) [%s]\" % (recall.mean(), recall.std(), classifier[1].__class__.__name__))\n",
        "  accuracy = cross_val_score(bagging, X, y, cv=10, scoring='accuracy')\n",
        "  print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (accuracy.mean(), accuracy.std(), classifier[1].__class__.__name__))\n",
        "\n",
        "  print(\"=================================================================\")\n",
        "  \n",
        "  \n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DecisionTreeClassifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.71      0.77       267\n",
            "           1       0.33      0.53      0.41        74\n",
            "\n",
            "    accuracy                           0.67       341\n",
            "   macro avg       0.59      0.62      0.59       341\n",
            "weighted avg       0.73      0.67      0.69       341\n",
            "\n",
            "Precision: 0.28 (+/- 0.13) [DecisionTreeClassifier]\n",
            "Recall: 0.27 (+/- 0.21) [DecisionTreeClassifier]\n",
            "Accuracy: 0.74 (+/- 0.10) [DecisionTreeClassifier]\n",
            "=================================================================\n",
            "MLPClassifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.92      0.87       267\n",
            "           1       0.49      0.27      0.35        74\n",
            "\n",
            "    accuracy                           0.78       341\n",
            "   macro avg       0.65      0.60      0.61       341\n",
            "weighted avg       0.75      0.78      0.75       341\n",
            "\n",
            "Precision: 0.36 (+/- 0.11) [MLPClassifier]\n",
            "Recall: 0.36 (+/- 0.10) [MLPClassifier]\n",
            "Accuracy: 0.74 (+/- 0.07) [MLPClassifier]\n",
            "=================================================================\n",
            "MultinomialNB\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.81      0.82       267\n",
            "           1       0.37      0.42      0.39        74\n",
            "\n",
            "    accuracy                           0.72       341\n",
            "   macro avg       0.60      0.61      0.61       341\n",
            "weighted avg       0.73      0.72      0.73       341\n",
            "\n",
            "Precision: 0.33 (+/- 0.11) [MultinomialNB]\n",
            "Recall: 0.48 (+/- 0.07) [MultinomialNB]\n",
            "Accuracy: 0.67 (+/- 0.07) [MultinomialNB]\n",
            "=================================================================\n",
            "RandomForestClassifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.98      0.90       267\n",
            "           1       0.78      0.28      0.42        74\n",
            "\n",
            "    accuracy                           0.83       341\n",
            "   macro avg       0.80      0.63      0.66       341\n",
            "weighted avg       0.82      0.83      0.79       341\n",
            "\n",
            "Precision: 0.63 (+/- 0.22) [RandomForestClassifier]\n",
            "Recall: 0.28 (+/- 0.08) [RandomForestClassifier]\n",
            "Accuracy: 0.82 (+/- 0.04) [RandomForestClassifier]\n",
            "=================================================================\n",
            "SGDClassifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.89      0.84       267\n",
            "           1       0.33      0.19      0.24        74\n",
            "\n",
            "    accuracy                           0.74       341\n",
            "   macro avg       0.56      0.54      0.54       341\n",
            "weighted avg       0.70      0.74      0.71       341\n",
            "\n",
            "Precision: 0.33 (+/- 0.08) [SGDClassifier]\n",
            "Recall: 0.32 (+/- 0.10) [SGDClassifier]\n",
            "Accuracy: 0.75 (+/- 0.04) [SGDClassifier]\n",
            "=================================================================\n",
            "SVC\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.96      0.89       267\n",
            "           1       0.62      0.27      0.38        74\n",
            "\n",
            "    accuracy                           0.81       341\n",
            "   macro avg       0.73      0.61      0.63       341\n",
            "weighted avg       0.78      0.81      0.78       341\n",
            "\n",
            "Precision: 0.53 (+/- 0.12) [SVC]\n",
            "Recall: 0.26 (+/- 0.11) [SVC]\n",
            "Accuracy: 0.81 (+/- 0.02) [SVC]\n",
            "=================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9CMX-aFIIXk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}