{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "colab_type": "code",
    "id": "1UCXyycm-Qh3",
    "outputId": "2f92d2b2-f09b-4d91-e230-91574ff83cb0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Collecting arff',\n",
       " '  Downloading https://files.pythonhosted.org/packages/50/de/62d4446c5a6e459052c2f2d9490c370ddb6abc0766547b4cef585913598d/arff-0.9.tar.gz',\n",
       " 'Building wheels for collected packages: arff',\n",
       " '  Building wheel for arff (setup.py) ... \\x1b[?25l\\x1b[?25hdone',\n",
       " '  Stored in directory: /root/.cache/pip/wheels/04/d0/70/2c73afedd3ac25c6085b528742c69b9587cbdfa67e5194583b',\n",
       " 'Successfully built arff',\n",
       " 'Installing collected packages: arff',\n",
       " 'Successfully installed arff-0.9']"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !! pip install arff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iFQac2wr-LNy"
   },
   "outputs": [],
   "source": [
    "import arff\n",
    "import time\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import attrgetter, itemgetter\n",
    "from io import StringIO\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import tree\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import make_scorer, confusion_matrix,classification_report,precision_recall_fscore_support as score, average_precision_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate\n",
    "from pickle import Pickler, Unpickler\n",
    "\n",
    "## training model\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "id": "vAIR83pK-xmT",
    "outputId": "c85fac67-ce14-4878-b779-c5c0a85627e9"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-203ac8e1c8e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/gdrive\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/gdrive\", force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D64VUJKt-ZiK"
   },
   "outputs": [],
   "source": [
    "root_path = \"gdrive/My Drive/Colab Notebooks/\"\n",
    "df = Unpickler(open(root_path + \"dataset/OffComBR3.sav\", 'rb')).load()\n",
    "\n",
    "X = df['sentence'].tolist()\n",
    "y = df['hate'].tolist()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                    X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qXNd24kK9h5U"
   },
   "outputs": [],
   "source": [
    "parameters_dt = {'tfidf__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "                 'tfidf__max_df': [0.2, 0.6, 0.8, 1.0],\n",
    "                 'tfidf__min_df': [1, 2, 5, 10],\n",
    "                 'tfidf__use_idf': [True, False],\n",
    "                 'tfidf__smooth_idf': [True, False],\n",
    "                 'tfidf__sublinear_tf': [True, False],\n",
    "                 'tfidf__strip_accents': ['ascii'],\n",
    "                  'clf__criterion': ['gini'],\n",
    "                  'clf__class_weight': [{0: 1, 1: 2}],\n",
    "                  'clf__min_samples_split': [3]\n",
    "                 }\n",
    "\n",
    "parameters_mlp = {'tfidf__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "                 'tfidf__max_df': [0.2, 0.6, 0.8, 1.0],\n",
    "                 'tfidf__min_df': [1, 2, 5, 10],\n",
    "                 'tfidf__use_idf': [True, False],\n",
    "                 'tfidf__smooth_idf': [True, False],\n",
    "                 'tfidf__sublinear_tf': [True, False],\n",
    "                 'tfidf__strip_accents': ['ascii'],\n",
    "                 'clf__activation': ['logistic'],\n",
    "                 'clf__solver': ['lbfgs'],\n",
    "                 'clf__alpha': [0]\n",
    "                }\n",
    "\n",
    "parameters_mnb = {'tfidf__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "                 'tfidf__max_df': [0.2, 0.6, 0.8, 1.0],\n",
    "                 'tfidf__min_df': [1, 2, 5, 10],\n",
    "                 'tfidf__use_idf': [True, False],\n",
    "                 'tfidf__smooth_idf': [True, False],\n",
    "                 'tfidf__sublinear_tf': [True, False],\n",
    "                 'tfidf__strip_accents': ['ascii'],\n",
    "                'clf__alpha': [0.1, 0.2],\n",
    "                'clf__fit_prior': [False],\n",
    "                }\n",
    "\n",
    "parameters_rf = {'tfidf__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "                 'tfidf__max_df': [0.2, 0.6, 0.8, 1.0],\n",
    "                 'tfidf__min_df': [1, 2, 5, 10],\n",
    "                 'tfidf__use_idf': [True, False],\n",
    "                 'tfidf__smooth_idf': [True, False],\n",
    "                 'tfidf__sublinear_tf': [True, False],\n",
    "                 'tfidf__strip_accents': ['ascii'],\n",
    "                 'clf__n_estimators': [100],\n",
    "                 'clf__max_depth': [None],\n",
    "                 'clf__min_samples_split': [2, 4],\n",
    "                 'clf__min_samples_leaf': [1, 2, 4]\n",
    "                }\n",
    "\n",
    "parameters_sgd = {'tfidf__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "                 'tfidf__max_df': [0.2, 0.6, 0.8, 1.0],\n",
    "                 'tfidf__min_df': [1, 2, 5, 10],\n",
    "                 'tfidf__use_idf': [True, False],\n",
    "                 'tfidf__smooth_idf': [True, False],\n",
    "                 'tfidf__sublinear_tf': [True, False],\n",
    "                 'tfidf__strip_accents': ['ascii'],\n",
    "                 'clf__alpha': [0.01],\n",
    "                 'clf__loss': ['perceptron'],\n",
    "                 'clf__penalty': ['none']\n",
    "                 }\n",
    "\n",
    "\n",
    "parameters_svc = {'tfidf__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "                 'tfidf__max_df': [0.2, 0.6, 0.8, 1.0],\n",
    "                 'tfidf__min_df': [1, 2, 5, 10],\n",
    "                 'tfidf__use_idf': [True, False],\n",
    "                 'tfidf__smooth_idf': [True, False],\n",
    "                 'tfidf__sublinear_tf': [True, False],\n",
    "                 'tfidf__strip_accents': ['ascii'],\n",
    "                 'clf__C': [4],\n",
    "                 'clf__kernel': ['linear'],\n",
    "                 'clf__shrinking': [True],\n",
    "                 'clf__probability': [True],\n",
    "                 'clf__tol': [1]\n",
    "                 }\n",
    "\n",
    "parameters = [parameters_dt, parameters_mlp, parameters_mnb, parameters_rf, parameters_sgd, parameters_svc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4zdsHaWAHvB2"
   },
   "outputs": [],
   "source": [
    "classifiers = [DecisionTreeClassifier(), MLPClassifier(), MultinomialNB(), RandomForestClassifier(), SGDClassifier(), SVC()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A_QO63H6PW-O"
   },
   "outputs": [],
   "source": [
    "def get_recal_1(y_true, y_pred):\n",
    "    precision, recall, fscore, support = score(y_true, y_pred)\n",
    "#     print(classification_report(y_true, y_pred))\n",
    "    return(recall[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "colab_type": "code",
    "id": "Ak2r8ZAUCDoo",
    "outputId": "3e03e71a-e602-4c09-9006-db4cf7f097c3"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classifiers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5e53bca7f73f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   cl = Pipeline([\n\u001b[1;32m      3\u001b[0m           \u001b[0;34m(\u001b[0m\u001b[0;34m'tfidf'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0;34m(\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         ])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classifiers' is not defined"
     ]
    }
   ],
   "source": [
    "for i, classifier in enumerate(classifiers):\n",
    "  cl = Pipeline([\n",
    "          ('tfidf',TfidfVectorizer()),\n",
    "          ('clf', classifier),\n",
    "        ])\n",
    "\n",
    "  gs_clf = GridSearchCV(cl, parameters[i], cv=2, iid=False, n_jobs=-1, scoring=make_scorer(get_recal_1))\n",
    "\n",
    "  gs_clf.fit(X, y)\n",
    "  print(classifier.__class__.__name__)\n",
    "  print(gs_clf.best_score_)\n",
    "  print(gs_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "exf-5n2tTw2M"
   },
   "outputs": [],
   "source": [
    "## classificadores com os melhores hiperparametros\n",
    "\n",
    "dt =  Pipeline([\n",
    "        ('tfidf',TfidfVectorizer(max_df = 0.6,\n",
    "                                 min_df = 1,\n",
    "                                 ngram_range = (1, 3),\n",
    "                                 smooth_idf = True,\n",
    "                                 strip_accents = 'ascii',\n",
    "                                 sublinear_tf = False,\n",
    "                                 use_idf = True)),\n",
    "        ('clf', DecisionTreeClassifier(class_weight= {0: 1, 1: 2}, criterion= 'gini', min_samples_split = 3)),\n",
    "        ])\n",
    "\n",
    "\n",
    "mlp =  Pipeline([\n",
    "        ('tfidf',TfidfVectorizer(max_df= 0.2,\n",
    "                                 min_df= 5,\n",
    "                                 ngram_range= (1, 2),\n",
    "                                 smooth_idf= True,\n",
    "                                 strip_accents= 'ascii',\n",
    "                                 sublinear_tf= False,\n",
    "                                 use_idf = False)),\n",
    "        ('clf', MLPClassifier(activation='logistic', alpha= 0, solver='lbfgs')),\n",
    "        ])\n",
    "\n",
    "mnb =  Pipeline([\n",
    "        ('tfidf',TfidfVectorizer(max_df= 0.6,\n",
    "                                 min_df= 5,\n",
    "                                 ngram_range= (1, 1),\n",
    "                                 smooth_idf= True,\n",
    "                                 strip_accents= 'ascii',\n",
    "                                 sublinear_tf= True,\n",
    "                                 use_idf = True)),\n",
    "        ('clf', MultinomialNB(alpha=0.1, fit_prior=False)),\n",
    "        ])\n",
    "\n",
    "rf = Pipeline([\n",
    "        ('tfidf',TfidfVectorizer(max_df= 0.2,\n",
    "                                 min_df= 2,\n",
    "                                 ngram_range= (1, 1),\n",
    "                                 smooth_idf= False,\n",
    "                                 strip_accents= 'ascii',\n",
    "                                 sublinear_tf= True,\n",
    "                                 use_idf = True)),\n",
    "        ('clf', RandomForestClassifier(max_depth=None, min_samples_leaf= 1, min_samples_split= 2, n_estimators=100)),\n",
    "        ])\n",
    "\n",
    "\n",
    "sgd = Pipeline([\n",
    "        ('tfidf',TfidfVectorizer(max_df= 0.2,\n",
    "                                 min_df= 10,\n",
    "                                 ngram_range= (1, 3),\n",
    "                                 smooth_idf= True,\n",
    "                                 strip_accents= 'ascii',\n",
    "                                 sublinear_tf= True,\n",
    "                                 use_idf = False)),\n",
    "        ('clf', SGDClassifier(alpha=0.01, loss='perceptron', penalty='none')),\n",
    "        ])\n",
    "\n",
    "\n",
    "svc =  Pipeline([\n",
    "        ('tfidf',TfidfVectorizer(max_df= 0.6,\n",
    "                                 min_df= 1,\n",
    "                                 ngram_range= (1, 1),\n",
    "                                 smooth_idf= True,\n",
    "                                 strip_accents= 'ascii',\n",
    "                                 sublinear_tf= False,\n",
    "                                 use_idf = True)),\n",
    "        ('clf', SVC(C=4, kernel ='linear', probability=True, shrinking=True, tol=1)),\n",
    "        ])\n",
    "\n",
    "all_improved_classifiers = [('dt', dt), ('mlp', mlp), ('mnb', mnb), ('rf', rf), ('sgd', sgd), ('svc', svc)]\n",
    "soft_improved_classifiers = [('mlp', mlp), ('mnb', mnb), ('rf', rf), ('svc', svc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "qSEmihzam0CV",
    "outputId": "6c4df701-c7ac-4623-cf0f-bbf146d406f3"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'improved_classifiers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3125e99336e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimproved_classifiers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m## Report normal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'improved_classifiers' is not defined"
     ]
    }
   ],
   "source": [
    "for classifier in improved_classifiers:\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    print(classifier['clf'].__class__.__name__)\n",
    "    ## Report normal\n",
    "    pred = classifier.predict(X_test)\n",
    "    print(classification_report(y_test, pred))\n",
    "\n",
    "    ## Métricas do CV:\n",
    "\n",
    "    recall_1 = cross_val_score(classifier, X, y, cv=10, scoring= make_scorer(get_recal_1))\n",
    "    print(\"Recall 1: %0.2f (+/- %0.2f) [%s]\" % (recall_1.mean(), recall_1.std(), classifier['clf'].__class__.__name__))\n",
    "    recall = cross_val_score(classifier, X, y, cv=10, scoring='recall')\n",
    "    print(\"Recall: %0.2f (+/- %0.2f) [%s]\" % (recall.mean(), recall.std(), classifier['clf'].__class__.__name__))\n",
    "    accuracy = cross_val_score(classifier, X, y, cv=10, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (accuracy.mean(), accuracy.std(), classifier['clf'].__class__.__name__))\n",
    "    precision = cross_val_score(classifier, X, y, cv=10, scoring='precision')\n",
    "    print(\"Precision: %0.2f (+/- %0.2f) [%s]\" % (precision.mean(), precision.std(), classifier['clf'].__class__.__name__))\n",
    "    print(\"=================================================================\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5TqBr_WOtvqS"
   },
   "outputs": [],
   "source": [
    "## classificadores com os melhores hiperparametros sem o tfidf\n",
    "\n",
    "# dt =  DecisionTreeClassifier(class_weight= {0: 1, 1: 2}, criterion= 'gini', min_samples_split = 3)\n",
    "# mlp = MLPClassifier(activation='logistic', alpha= 0, solver='lbfgs')\n",
    "# mnb =  MultinomialNB(alpha=0.1, fit_prior=False)\n",
    "# rf = RandomForestClassifier(max_depth=None, min_samples_leaf= 1, min_samples_split= 2, n_estimators=100)\n",
    "# sgd = SGDClassifier(alpha=0.01, loss='perceptron', penalty='none')\n",
    "# svc = SVC(C=4, kernel ='linear', probability=True, shrinking=True, tol=1)\n",
    "\n",
    "# only_classifiers = [dt, mlp, mnb, rf, sgd, svc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "swINe0sIJnEU",
    "outputId": "e43718c1-ad40-45d2-d55e-6e42385011b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5497619047619048\n",
      "{'voting__voting': 'hard', 'voting__weights': [0, 0, 1, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "### TESTANDO APENAS VOTING = HARD\n",
    "voting = Pipeline([\n",
    "    ('voting', VotingClassifier(estimators = all_improved_classifiers))\n",
    "    \n",
    "])\n",
    "\n",
    "\n",
    "def combinations_on_off(num_classifiers):\n",
    "    return [[int(x) for x in list(\"{0:0b}\".format(i).zfill(num_classifiers))]\n",
    "            for i in range(1, 2 ** num_classifiers)]\n",
    "\n",
    "\n",
    "parameters_voting = {\n",
    "                      'voting__voting': ['hard'],\n",
    "                      'voting__weights': combinations_on_off(len(all_improved_classifiers))\n",
    "                }\n",
    "\n",
    "\n",
    "gridVoting = GridSearchCV(voting, parameters_voting, cv=10, iid=False, n_jobs=-1, scoring=make_scorer(get_recal_1))\n",
    "gridVoting.fit(X, y)\n",
    "print(gridVoting.best_score_)\n",
    "print(gridVoting.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "Lh7POy55-ija",
    "outputId": "e44f5cb6-221d-439f-9e5e-4a2e9a6016ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5497619047619048\n",
      "{'voting__voting': 'soft', 'voting__weights': [0, 1, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "### TESTANDO APENAS VOTING = SOFT\n",
    "voting = Pipeline([\n",
    "    ('voting', VotingClassifier(estimators = soft_improved_classifiers))\n",
    "    \n",
    "])\n",
    "\n",
    "\n",
    "parameters_voting = {\n",
    "                      'voting__voting': ['soft'],\n",
    "                      'voting__weights': combinations_on_off(len(soft_improved_classifiers))\n",
    "                }\n",
    "\n",
    "\n",
    "gridVoting2 = GridSearchCV(voting, parameters_voting, cv=10, iid=False, n_jobs=-1, scoring='recall')\n",
    "gridVoting2.fit(X, y)\n",
    "print(gridVoting2.best_score_)\n",
    "print(gridVoting2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "X1HjDuhY-lFr",
    "outputId": "be4dbfbc-306a-4277-c9f7-1b89f9065506"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8208985916995625\n",
      "{'voting__voting': 'soft', 'voting__weights': [0, 0, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "### TESTANDO APENAS VOTING = SOFT\n",
    "voting = Pipeline([\n",
    "    ('voting', VotingClassifier(estimators = soft_improved_classifiers))\n",
    "    \n",
    "])\n",
    "\n",
    "\n",
    "parameters_voting = {\n",
    "                      'voting__voting': ['soft'],\n",
    "                      'voting__weights': combinations_on_off(len(soft_improved_classifiers))\n",
    "                }\n",
    "\n",
    "\n",
    "gridVoting3 = GridSearchCV(voting, parameters_voting, cv=10, iid=False, n_jobs=-1, scoring='accuracy')\n",
    "gridVoting3.fit(X, y)\n",
    "print(gridVoting3.best_score_)\n",
    "print(gridVoting3.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "oSj9N7WFVgWG",
    "outputId": "76e53868-3f2e-479a-d3f9-86d79a37e85b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6470183982683982\n",
      "{'voting__voting': 'soft', 'voting__weights': [0, 0, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "### TESTANDO APENAS VOTING = SOFT\n",
    "voting = Pipeline([\n",
    "    ('voting', VotingClassifier(estimators = soft_improved_classifiers))\n",
    "    \n",
    "])\n",
    "\n",
    "\n",
    "parameters_voting = {\n",
    "                      'voting__voting': ['soft'],\n",
    "                      'voting__weights': combinations_on_off(len(soft_improved_classifiers))\n",
    "                }\n",
    "\n",
    "\n",
    "gridVoting3 = GridSearchCV(voting, parameters_voting, cv=10, iid=False, n_jobs=-1, scoring='accuracy')\n",
    "gridVoting3.fit(X, y)\n",
    "print(gridVoting3.best_score_)\n",
    "print(gridVoting3.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "xpTrP3ImW7bS",
    "outputId": "3ac02f77-400b-4c23-a79f-794844744100"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5497619047619048\n",
      "{'voting__voting': 'soft', 'voting__weights': [1, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "voting = Pipeline([\n",
    "    ('voting', VotingClassifier(estimators = [('mnb', mnb), ('mlp', mlp), ('svc', svc)]))\n",
    "    \n",
    "])\n",
    "\n",
    "\n",
    "parameters_voting = {\n",
    "                      'voting__voting': ['soft'],\n",
    "                      'voting__weights': [[0,0,1],\n",
    "                                         [0,1,0],\n",
    "                                         [1,0,0],\n",
    "                                         [1,1,1],\n",
    "                                         [1,1,2],\n",
    "                                         [1,2,1],\n",
    "                                         [2,1,1],\n",
    "                                         [2,2,1],\n",
    "                                         [1,2,2]]\n",
    "                }\n",
    "\n",
    "\n",
    "gridVoting3 = GridSearchCV(voting, parameters_voting, cv=10, iid=False, n_jobs=-1, scoring='recall')\n",
    "gridVoting3.fit(X, y)\n",
    "print(gridVoting3.best_score_)\n",
    "print(gridVoting3.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "colab_type": "code",
    "id": "Impsy1DFXPkI",
    "outputId": "4eec377e-1231-4383-8df1-f839e4d5c548"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=0.6, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 3), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents='ascii',\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_patter...\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('clf',\n",
       "                 DecisionTreeClassifier(class_weight={0: 1, 1: 2},\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features=None, max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=3,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        presort=False, random_state=None,\n",
       "                                        splitter='best'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  mnb.fit(X_train, y_train)\n",
    "  rf.fit(X_train, y_train)\n",
    "  sgd.fit(X_train, y_train)\n",
    "  svc.fit(X_train, y_train)\n",
    "  dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3DGdbH5Tn57I"
   },
   "outputs": [],
   "source": [
    "def classifica(txt):\n",
    "  result = []\n",
    "  for t in txt:\n",
    "    if (mnb.predict([t]) == 1) or (rf.predict([t]) == 1) or (svc.predict([t]) == 1):\n",
    "      result.append(1)\n",
    "    else:\n",
    "      result.append(0)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "colab_type": "code",
    "id": "nrm6aXHtp-Ne",
    "outputId": "58f4d738-beef-4dba-d2ac-8716f4604467"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.77      0.82       267\n",
      "           1       0.41      0.57      0.47        74\n",
      "\n",
      "    accuracy                           0.73       341\n",
      "   macro avg       0.64      0.67      0.65       341\n",
      "weighted avg       0.77      0.73      0.74       341\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = classifica(X_test)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C8T4KsPOqTjW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TCC_experiments.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
