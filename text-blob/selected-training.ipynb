{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from stop_words import get_stop_words\n",
    "import nltk\n",
    "import unicodedata\n",
    "import re\n",
    "from textblob.classifiers import NaiveBayesClassifier, DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "314"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../utils/classificated_texts.csv')\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>me copio de cece no me ignoréis</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dicas p não passar raiva sempre que vou arruma...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aquele momento que você se apaixona pela sua v...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Não to com ele agr kkkkkkkkk</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sou pobre</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text classification\n",
       "0                    me copio de cece no me ignoréis            neg\n",
       "1  dicas p não passar raiva sempre que vou arruma...            neg\n",
       "2  Aquele momento que você se apaixona pela sua v...            pos\n",
       "3                       Não to com ele agr kkkkkkkkk            neg\n",
       "4                                          Sou pobre            neg"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accent_from_words(word):\n",
    "    nfkd = unicodedata.normalize('NFKD', word)\n",
    "    withouth_accent = u\"\".join([c for c in nfkd if not unicodedata.combining(c)])\n",
    "    return re.sub('[^a-zA-Z0-9 \\\\\\]', '', withouth_accent)\n",
    "\n",
    "def normalize(df):\n",
    "    stemmer = nltk.stem.RSLPStemmer()\n",
    "    stop_words = get_stop_words('pt')\n",
    "    for index, row in df.iterrows():\n",
    "        split = str(row['text']).split()\n",
    "        split = [word.lower() for word in split]\n",
    "#         split = [stemmer.stem(word) for word in split]\n",
    "        for word in stop_words:\n",
    "            if word in split:\n",
    "                split.remove(word)             \n",
    "        split = [remove_accent_from_words(word) for word in split]\n",
    "        row['sentence'] = ' '.join(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [tuple(x) for x in train.to_records(index=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_train = []\n",
    "for i in range(0, 214):\n",
    "    to_train.append(random.choice(train))\n",
    "\n",
    "to_test = []\n",
    "for i in range(0, 100):\n",
    "    to_test.append(random.choice(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = DecisionTreeClassifier(to_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.accuracy(to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
